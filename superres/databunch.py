# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/01_databunch.ipynb (unless otherwise specified).

__all__ = ['resize_image', 'lr_image', 'crop_center_image', 'split_luminance', 'after_open_image', 'get_sr_transforms',
           'create_sr_databunch', 'extract_y', 'denorm_img', 'm_psnr', 'm_ssim', 'reconstruct_image', 'sr_predict',
           'get_metrics', 'fmt_metrics', 'mean_metrics', 'sr_test', 'sr_test_upscale']

# Cell
import PIL
from pathlib import PosixPath

# Cell
from fastai import *
from fastai.vision import *
from fastai.callbacks import *
#from fastai.metrics import psnr

# Cell
from skimage.metrics import peak_signal_noise_ratio
from skimage.metrics import structural_similarity

# Cell
def resize_image(img:PIL.Image, size:int)->PIL.Image:
    """ resize PIL-image """
    w, h = img.size
    if w == size and h == size: return img
    else: return img.resize((size, size), PIL.Image.BICUBIC)

# Cell
def lr_image(img:PIL.Image, scale:int, sizeup:bool=False, size:int=None)->PIL.Image:
    """
    create low resolution image.
    sizeup=False : size=original_size // scale
    sizeup=True and size=size: upsize to size.
    sizeup=True and size=None: upsize to original size.
    """
    w, h = img.size
    img = img.resize((w // scale, h // scale), PIL.Image.BICUBIC)
    if sizeup:
        img = img.resize((size, size), PIL.Image.BICUBIC) if size else img.resize((w, h), PIL.Image.BICUBIC)
    return img

# Cell
def crop_center_image(img:PIL.Image, size:int)->PIL.Image:
    """ crop center PIL-image """
    w, h = img.size
    if size == w and size == h:
        return img
    else:
        return img.crop(((w - size) // 2,(h - size) // 2, (w + size) // 2, (h + size) // 2))

# Cell
def split_luminance(img:PIL.Image)->PIL.Image:
    """ Y channel of YCbCr-Image """
    img, _, _ = img.split()
    return img

# Cell
def after_open_image(img:PIL.Image, size, scale:int=1, sizeup:bool=False, crop:bool=True, luminance:bool=False)->PIL.Image:
    """ after_open function of ImageImageList """
    w, h = img.size
    if scale > 1: img = lr_image(img, scale, sizeup=sizeup)
    if crop: img = crop_center_image(img, size)
    if luminance: img = split_luminance(img)
    return img

# Cell
def get_sr_transforms(size, max_lighting:float=0.2, p_lighting:float=0.75, xtra_tfms:Optional[Collection[Transform]]=None)->'Collection[Transform]':
    """ trainsorms for super-resolution """
    res = [crop(size=size)]
    if max_lighting:
        res.append(brightness(change=(0.5*(1-max_lighting), 0.5*(1+max_lighting)), p=p_lighting))
        res.append(contrast(scale=(1-max_lighting, 1/(1-max_lighting)), p=p_lighting))
    #       train                   , valid
    return (res + listify(xtra_tfms), [crop(size=size)])

# Cell
def create_sr_databunch(data_path:PosixPath, in_size:int, out_size:int, scale:int, bs:int, convert_mode:str='RGB', seed:int=1234)->'DataBunch':
    """ create databunch for super-resolution """
    luminance = convert_mode == 'YCbCr'
    sizeup = in_size == out_size

    src = (ImageImageList.from_folder(data_path, convert_mode=convert_mode,
                                      after_open=partial(after_open_image, size=in_size, scale=scale, sizeup=sizeup, luminance=luminance))
        .split_by_rand_pct(seed=seed)
        .label_from_func((lambda x: x), label_cls=ImageImageList, convert_mode=convert_mode,
                         after_open=partial(after_open_image, size=out_size, luminance=luminance)))

    data = (src.transform(get_sr_transforms(size=in_size), tfm_y=True)
        .transform_y(get_sr_transforms(size=out_size, max_lighting=0))
        .databunch(path=Path('.'), bs=bs))
    if luminance:
        data.normalize(do_y=True)
    else:
        data.normalize(imagenet_stats, do_y=True)
    return data

# Cell
def extract_y(img:Tensor)->'Tensor':
    """ extract luminance. img is RGB, input range is [0...1], output range is [0..255] """
    # return  img[0] * 65.481 / 255 + img[1] * 128.553 / 255 + img[2] * 24.966 /255 + 16
    return  img[0] * 65.481 + img[1] * 128.553 + img[2] * 24.966 + 16

# Cell
imagenet_mean, imagenet_std = vision.data.imagenet_stats

def denorm_img(x:Tensor)->'Tensor':
    """ de normalize image """
    img = vision.data.denormalize(x, tensor(imagenet_mean), tensor(imagenet_std))
    img = img.clamp(min=0, max=1)
    #img = img.permute(1,2,0).numpy() * 255
    img = img.permute(1,2,0).numpy()
    img = extract_y(img)
    return img

# Cell
def m_psnr(img1:Tensor, img2:Tensor)->'Tensor':
    """ metrics: peak_signal_noise_ratio """
    # n, c, h, w = img1.shape
    psnrs = []
    for i1, i2 in zip(img1, img2):
        psnrs.append(peak_signal_noise_ratio(denorm_img(i1), denorm_img(i2), data_range=255))
    return tensor(sum(psnrs) / len(psnrs)) # mean

# Cell
def m_ssim(img1, img2)->'Tensor':
    """ metrics: structural_similarity """
    # n, c, h, w = img1.shape
    ssims = []
    for i1, i2 in zip(img1, img2):
        ssims.append(structural_similarity(denorm_img(i1), denorm_img(i2), multichannel=True))
        #ssims.append(structural_similarity(denorm_img(i1), denorm_img(i2)))
    return tensor(sum(ssims) / len(ssims)) # mean

# Cell
def reconstruct_image(t:Tensor)->"Image":
    """ create Image from Tensor """
    return Image(t.float().clamp(min=0, max=1))

# Cell
def sr_predict(learn:Learner, item:ItemBase)->"ItemBase":
    """ predict for super-resolution """
    batch = learn.data.one_item(item)
    res = learn.pred_batch(batch=batch)
    raw_pred = grab_idx(res, 0)
    raw_pred = learn.data.denorm(raw_pred)
    pred = reconstruct_image(raw_pred)
    return pred

# Cell
def get_metrics(img1:Tensor, img2:Tensor)->'[int, int]':
    """ psnr and ssim """
    #img1_y = extract_y(img1)
    #img2_y = extract_y(img2)
    psnr = peak_signal_noise_ratio(img1, img2)
    ssim = structural_similarity(img1, img2, multichannel=True)
    return [psnr, ssim]

# Cell
def fmt_metrics(metrics):
    """ format of metrics """
    return f'PSNR:{metrics[0]:.2f},SSIM:{metrics[1]:.4f}'

# Cell
def mean_metrics(metrics):
    """ mean of metrics """
    return np.asarray(metrics).mean(axis=0)

# Cell
def sr_test(learn:Learner, il_test_x:ImageImageList, il_test_y:ImageImageList, model_name:str, cmap:str=None):
    """ test for super-resolution """
    pred_metrics = []
    bicubic_metrics = []
    for x, y in zip(il_test_x, il_test_y):
        pred = sr_predict(learn, x)
        pred_metrics.append(get_metrics(image2np(y.px), image2np(pred.px)))
        bicubic_metrics.append(get_metrics(image2np(y.px), image2np(x.px)))
        fig, axs = plt.subplots(1, 3, figsize=(15, 15))
        x.show(ax=axs[0], title=f'bicubic({fmt_metrics(bicubic_metrics[-1])})', cmap=cmap)
        pred.show(ax=axs[1], title=f'{model_name}({fmt_metrics(pred_metrics[-1])})', cmap=cmap)
        y.show(ax=axs[2], title='Ground Truth', cmap=cmap)
    print('bicubic:', fmt_metrics(mean_metrics(bicubic_metrics)))
    print(f'{model_name}:\t', fmt_metrics(mean_metrics(pred_metrics)))

# Cell
def sr_test_upscale(learn:Learner, il_x:ImageImageList, il_y:ImageImageList, il_x_up:ImageImageList, model_name:str, cmap:str=None):
    """ model で upscale する SR のテストを実施する """
    pred_metrics = []
    bicubic_metrics = []
    for x, y, z in zip(il_x, il_y, il_x_up):
        pred = sr_predict(learn, x)
        pred_metrics.append(get_metrics(image2np(y.px), image2np(pred.px)))
        bicubic_metrics.append(get_metrics(image2np(y.px), image2np(z.px)))
        fig, axs = plt.subplots(1, 3, figsize=(15, 15))
        x.show(ax=axs[0], title=f'bicubic({fmt_metrics(bicubic_metrics[-1])})',cmap=cmap)
        pred.show(ax=axs[1], title=f'{model_name}({fmt_metrics(pred_metrics[-1])})', cmap=cmap)
        y.show(ax=axs[2], title='Ground Truth', cmap=cmap)
    print('bicubic:', fmt_metrics(mean_metrics(bicubic_metrics)))
    print(f'{model_name}:\t', fmt_metrics(mean_metrics(pred_metrics)))